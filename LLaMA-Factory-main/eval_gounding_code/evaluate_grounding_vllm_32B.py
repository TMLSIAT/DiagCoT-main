#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨VLLMéƒ¨ç½²çš„32Bæ¨¡å‹è¿›è¡ŒåŒ»å­¦å½±åƒæ ‡æ¡†ä»»åŠ¡è¯„ä¼°
é€šè¿‡OpenAI APIæ¥å£è°ƒç”¨æœ¬åœ°VLLMæœåŠ¡
ç»“åˆæ ‡æ¡†ä»»åŠ¡è¯„ä¼°å’ŒVLLM APIè°ƒç”¨åŠŸèƒ½
"""

import json
import os
import re
import base64
import argparse
import numpy as np
from tqdm import tqdm
from typing import List, Dict, Tuple, Any, Optional
from openai import OpenAI
from retrying import retry
import warnings
warnings.filterwarnings("ignore")

def encode_image(image_path):
    """
    å°†å›¾åƒæ–‡ä»¶ç¼–ç ä¸ºbase64æ ¼å¼
    
    Args:
        image_path (str): å›¾åƒæ–‡ä»¶è·¯å¾„
        
    Returns:
        str: base64ç¼–ç çš„å›¾åƒæ•°æ®
    """
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode("utf-8")

class VLLMGroundingClassifier:
    """
    ä½¿ç”¨VLLM APIçš„åŒ»å­¦å½±åƒæ ‡æ¡†åˆ†ç±»å™¨
    """
    
    def __init__(self, model_name, api_key="qwen-abc123", api_url="http://127.0.0.1:8000/v1"):
        """
        åˆå§‹åŒ–VLLMæ ‡æ¡†åˆ†ç±»å™¨
        
        Args:
            model_name (str): æ¨¡å‹åç§°
            api_key (str): APIå¯†é’¥
            api_url (str): APIæœåŠ¡åœ°å€
        """
        self.model_name = model_name
        self.api_key = api_key
        self.api_url = api_url
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=self.api_url,
        )
        print(f"åˆå§‹åŒ–VLLMæ ‡æ¡†åˆ†ç±»å™¨ï¼Œæ¨¡å‹: {model_name}, APIåœ°å€: {api_url}")

    def _construct_messages(self, image_path):
        """
        æ„é€ å‘é€ç»™æ¨¡å‹çš„æ¶ˆæ¯æ ¼å¼
        
        Args:
            image_path (str): å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            list: æ ¼å¼åŒ–çš„æ¶ˆæ¯åˆ—è¡¨
        """
        # å°†å›¾åƒç¼–ç ä¸ºbase64
        base64_image = encode_image(image_path)
        
        return [{
            "role": "user",
            "content": [
                {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}"
                    }
                },
                {
                    "type": "text",
                    "text": "Please detect and locate any lung opacity regions in this chest X-ray image.\n\nDetection Guidelines:\n- Look for areas of increased density in the lung fields\n- Consider consolidation, infiltrates, or other opacity patterns\n- Ensure coordinates are within image boundaries\n- Provide precise (x1,y1),(x2,y2) coordinates\n\nOutput Format:\n\"The detected lung opacity regions are: Lung Opacity: <box>(x1,y1),(x2,y2)</box>\"\n\nIf no opacity is detected, output: \"The detected lung opacity regions are: No lung opacity regions detected.\" Output the thinking process in <think> </think>, and output the final detection result within the <answer> </answer>. Following \"<think></think>\\n<answer></answer> \" format."
                }
            ]
        }]

    @retry(wait_fixed=3000, stop_max_attempt_number=3)
    def _retry_call(self, messages):
        """
        å¸¦é‡è¯•æœºåˆ¶çš„APIè°ƒç”¨
        
        Args:
            messages (list): æ¶ˆæ¯åˆ—è¡¨
            
        Returns:
            str: æ¨¡å‹ç”Ÿæˆçš„å“åº”
        """
        response = self.client.chat.completions.create(
            model=self.model_name,
            messages=messages,
            # max_tokens=4096,
        )
        return response.choices[0].message.content

    def detect(self, image_path):
        """
        å¯¹åŒ»å­¦å½±åƒè¿›è¡Œæ ‡æ¡†æ£€æµ‹
        
        Args:
            image_path (str): å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            str: æ£€æµ‹ç»“æœ
        """
        try:
            # æ„é€ æ¶ˆæ¯
            messages = self._construct_messages(image_path)
            
            # è°ƒç”¨APIè¿›è¡Œæ£€æµ‹
            response = self._retry_call(messages)
            
            return response if response else ""
            
        except Exception as e:
            print(f"æ£€æµ‹æ—¶å‡ºé”™ {image_path}: {str(e)}")
            return ""

def extract_answer_from_tags(text: str) -> str:
    """
    ä»æ–‡æœ¬ä¸­æå–<answer></answer>æ ‡ç­¾å†…çš„å†…å®¹
    å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡ç­¾ï¼Œè¿”å›åŸå§‹æ–‡æœ¬
    
    Args:
        text (str): è¾“å…¥æ–‡æœ¬
        
    Returns:
        str: æå–çš„ç­”æ¡ˆå†…å®¹
    """
    answer_pattern = r'<answer>(.*?)</answer>'
    match = re.search(answer_pattern, text, re.DOTALL)
    if match:
        return match.group(1).strip()
    return text.strip()

def parse_bbox_from_text(text: str) -> List[Tuple[float, float, float, float]]:
    """
    ä»æ¨¡å‹è¾“å‡ºæ–‡æœ¬ä¸­è§£æbboxåæ ‡
    æ ¼å¼: <box>(x1,y1),(x2,y2)</box>
    æ”¯æŒç›¸å¯¹åæ ‡(0-1)å’Œç»å¯¹åæ ‡(>1)
    
    Args:
        text (str): è¾“å…¥æ–‡æœ¬
        
    Returns:
        List[Tuple[float, float, float, float]]: ç›¸å¯¹åæ ‡æ ¼å¼çš„bboxåˆ—è¡¨
    """
    # é¦–å…ˆæå–answeræ ‡ç­¾å†…çš„å†…å®¹
    answer_text = extract_answer_from_tags(text)
    print("answer_text:", answer_text)
    
    # ç»Ÿä¸€çš„åæ ‡åŒ¹é…æ ¼å¼ï¼Œæ”¯æŒæ•´æ•°å’Œå°æ•°
    box_pattern = r'<box>\(([0-9.]+),([0-9.]+)\),\(([0-9.]+),([0-9.]+)\)</box>'
    matches = re.findall(box_pattern, answer_text)
    
    bboxes = []
    
    for match in matches:
        x1, y1, x2, y2 = map(float, match)
        
        # åˆ¤æ–­æ˜¯ç›¸å¯¹åæ ‡è¿˜æ˜¯ç»å¯¹åæ ‡
        # å¦‚æœæ‰€æœ‰åæ ‡éƒ½åœ¨0-1èŒƒå›´å†…ï¼Œè®¤ä¸ºæ˜¯ç›¸å¯¹åæ ‡
        if 0 <= x1 <= 1 and 0 <= y1 <= 1 and 0 <= x2 <= 1 and 0 <= y2 <= 1:
            # ç›¸å¯¹åæ ‡ï¼Œç›´æ¥ä½¿ç”¨
            x1_rel, y1_rel, x2_rel, y2_rel = x1, y1, x2, y2
        else:
            # ç»å¯¹åæ ‡ï¼Œè½¬æ¢ä¸ºç›¸å¯¹åæ ‡ï¼ˆé™¤ä»¥1000ï¼‰
            x1_rel = x1 / 1000.0
            y1_rel = y1 / 1000.0
            x2_rel = x2 / 1000.0
            y2_rel = y2 / 1000.0
            
            # æ£€æŸ¥è½¬æ¢åçš„åæ ‡æ˜¯å¦åˆç†
            if not (0 <= x1_rel <= 1 and 0 <= y1_rel <= 1 and 0 <= x2_rel <= 1 and 0 <= y2_rel <= 1):
                # å¦‚æœè½¬æ¢åä»ä¸åœ¨0-1èŒƒå›´å†…ï¼Œè·³è¿‡è¿™ä¸ªè¾¹ç•Œæ¡†
                continue
        
        # ç¡®ä¿åæ ‡é¡ºåºæ­£ç¡® (å·¦ä¸Šè§’åˆ°å³ä¸‹è§’)
        x1_rel, x2_rel = min(x1_rel, x2_rel), max(x1_rel, x2_rel)
        y1_rel, y2_rel = min(y1_rel, y2_rel), max(y1_rel, y2_rel)
        
        # æ£€æŸ¥è¾¹ç•Œæ¡†æ˜¯å¦æœ‰æ•ˆï¼ˆå®½åº¦å’Œé«˜åº¦å¤§äº0ï¼‰
        if x2_rel > x1_rel and y2_rel > y1_rel:
            bboxes.append((x1_rel, y1_rel, x2_rel, y2_rel))
    
    return bboxes

def parse_prediction_text_improved(text: str) -> Tuple[List[Tuple[float, float, float, float]], bool]:
    """
    æ”¹è¿›çš„é¢„æµ‹æ–‡æœ¬è§£æå‡½æ•°
    æ”¯æŒä»<answer></answer>æ ‡ç­¾ä¸­æå–ç­”æ¡ˆ
    
    Args:
        text (str): é¢„æµ‹æ–‡æœ¬
        
    Returns:
        Tuple[List[Tuple[float, float, float, float]], bool]: (bboxåˆ—è¡¨, æ˜¯å¦æœ‰å¼‚å¸¸)
    """
    # é¦–å…ˆæå–answeræ ‡ç­¾å†…çš„å†…å®¹
    answer_text = extract_answer_from_tags(text)
    
    # æ£€æŸ¥æ˜¯å¦æ˜ç¡®è¡¨ç¤ºæ²¡æœ‰æ£€æµ‹åˆ°å¼‚å¸¸
    no_finding_patterns = [
        "no lung opacity regions detected",
        "no abnormality detected",
        "no abnormal areas found",
        "no opacity regions found",
        "normal chest x-ray",
        "no findings",
        "no lesions detected"
    ]
    
    text_lower = answer_text.lower()
    has_no_finding = any(pattern in text_lower for pattern in no_finding_patterns)
    
    # è§£æbounding box
    bboxes = parse_bbox_from_text(text)
    
    # åˆ¤æ–­æ˜¯å¦æœ‰å¼‚å¸¸
    has_abnormality = len(bboxes) > 0 or not has_no_finding
    
    return bboxes, has_abnormality

def calculate_iou(bbox1: Tuple[float, float, float, float], 
                  bbox2: Tuple[float, float, float, float]) -> float:
    """
    è®¡ç®—ä¸¤ä¸ªbboxçš„IoU
    
    Args:
        bbox1 (Tuple[float, float, float, float]): ç¬¬ä¸€ä¸ªbbox (x1, y1, x2, y2)
        bbox2 (Tuple[float, float, float, float]): ç¬¬äºŒä¸ªbbox (x1, y1, x2, y2)
        
    Returns:
        float: IoUåˆ†æ•°
    """
    x1_1, y1_1, x2_1, y2_1 = bbox1
    x1_2, y1_2, x2_2, y2_2 = bbox2
    
    # è®¡ç®—äº¤é›†
    x_left = max(x1_1, x1_2)
    y_top = max(y1_1, y1_2)
    x_right = min(x2_1, x2_2)
    y_bottom = min(y2_1, y2_2)
    
    if x_right < x_left or y_bottom < y_top:
        return 0.0
    
    intersection = (x_right - x_left) * (y_bottom - y_top)
    
    # è®¡ç®—å„è‡ªé¢ç§¯
    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
    
    # è®¡ç®—å¹¶é›†
    union = area1 + area2 - intersection
    
    if union == 0:
        return 0.0
    
    return intersection / union

def evaluate_detection_improved(pred_bboxes: List[Tuple[float, float, float, float]], 
                               gt_bboxes: List[Tuple[float, float, float, float]], 
                               pred_has_abnormality: bool,
                               gt_has_abnormality: bool,
                               iou_threshold: float = 0.5) -> Dict[str, Any]:
    """
    æ”¹è¿›çš„æ£€æµ‹è¯„ä¼°å‡½æ•°
    å¤„ç†ä¸¤ç§æƒ…å†µï¼šæœ‰æ¡†å’Œæ— æ¡†
    
    Args:
        pred_bboxes: é¢„æµ‹çš„bboxåˆ—è¡¨
        gt_bboxes: çœŸå®çš„bboxåˆ—è¡¨
        pred_has_abnormality: é¢„æµ‹æ˜¯å¦æœ‰å¼‚å¸¸
        gt_has_abnormality: çœŸå®æ˜¯å¦æœ‰å¼‚å¸¸
        iou_threshold: IoUé˜ˆå€¼
        
    Returns:
        Dict[str, Any]: è¯„ä¼°ç»“æœ
    """
    # æƒ…å†µ1: çœŸå®æ— å¼‚å¸¸ï¼Œé¢„æµ‹æ— å¼‚å¸¸ -> æ­£ç¡®
    if not gt_has_abnormality and not pred_has_abnormality:
        return {
            "correct": True,
            "case": "true_negative",
            "precision": 1.0,
            "recall": 1.0,
            "f1": 1.0,
            "iou_score": 1.0
        }
    
    # æƒ…å†µ2: çœŸå®æ— å¼‚å¸¸ï¼Œé¢„æµ‹æœ‰å¼‚å¸¸ -> é”™è¯¯
    if not gt_has_abnormality and pred_has_abnormality:
        return {
            "correct": False,
            "case": "false_positive",
            "precision": 0.0,
            "recall": 1.0,
            "f1": 0.0,
            "iou_score": 0.0
        }
    
    # æƒ…å†µ3: çœŸå®æœ‰å¼‚å¸¸ï¼Œé¢„æµ‹æ— å¼‚å¸¸ -> é”™è¯¯
    if gt_has_abnormality and not pred_has_abnormality:
        return {
            "correct": False,
            "case": "false_negative",
            "precision": 1.0,
            "recall": 0.0,
            "f1": 0.0,
            "iou_score": 0.0
        }
    
    # æƒ…å†µ4: çœŸå®æœ‰å¼‚å¸¸ï¼Œé¢„æµ‹æœ‰å¼‚å¸¸ -> éœ€è¦è®¡ç®—IoU
    if gt_has_abnormality and pred_has_abnormality:
        if len(pred_bboxes) == 0 or len(gt_bboxes) == 0:
            return {
                "correct": False,
                "case": "bbox_mismatch",
                "precision": 0.0,
                "recall": 0.0,
                "f1": 0.0,
                "iou_score": 0.0
            }
        
        # è®¡ç®—æ¯ä¸ªé¢„æµ‹æ¡†ä¸çœŸå®æ¡†çš„æœ€å¤§IoU
        matched_gt = set()
        true_positives = 0
        max_iou = 0.0
        
        for pred_bbox in pred_bboxes:
            pred_max_iou = 0.0
            best_gt_idx = -1
            
            for gt_idx, gt_bbox in enumerate(gt_bboxes):
                if gt_idx in matched_gt:
                    continue
                
                iou = calculate_iou(pred_bbox, gt_bbox)
                if iou > pred_max_iou:
                    pred_max_iou = iou
                    best_gt_idx = gt_idx
            
            if pred_max_iou > max_iou:
                max_iou = pred_max_iou
            
            if pred_max_iou >= iou_threshold and best_gt_idx != -1:
                matched_gt.add(best_gt_idx)
                true_positives += 1
        
        precision = true_positives / len(pred_bboxes) if len(pred_bboxes) > 0 else 0.0
        recall = true_positives / len(gt_bboxes) if len(gt_bboxes) > 0 else 0.0
        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0
        
        # åˆ¤æ–­æ˜¯å¦æ­£ç¡® (IoUé˜ˆå€¼å’ŒF1åˆ†æ•°)
        is_correct = max_iou >= iou_threshold and f1 > 0.5
        
        return {
            "correct": is_correct,
            "case": "true_positive" if is_correct else "low_iou_or_f1",
            "precision": precision,
            "recall": recall,
            "f1": f1,
            "iou_score": max_iou,
            "max_iou": max_iou,
            "matched_pairs": true_positives,
            "total_predictions": len(pred_bboxes),
            "total_ground_truths": len(gt_bboxes)
        }
    
    # å…œåº•è¿”å›
    return {
        "correct": False,
        "case": "unknown",
        "precision": 0.0,
        "recall": 0.0,
        "f1": 0.0,
        "iou_score": 0.0
    }

def load_test_data_improved(test_file: str) -> List[Dict[str, Any]]:
    """
    æ”¹è¿›çš„æµ‹è¯•æ•°æ®åŠ è½½å‡½æ•°
    æ”¯æŒä»<answer></answer>æ ‡ç­¾ä¸­æå–ç­”æ¡ˆ
    
    Args:
        test_file (str): æµ‹è¯•æ–‡ä»¶è·¯å¾„
        
    Returns:
        List[Dict[str, Any]]: å¤„ç†åçš„æµ‹è¯•æ•°æ®
    """
    print(f"æ­£åœ¨åŠ è½½æµ‹è¯•æ•°æ®: {test_file}")
    with open(test_file, 'r', encoding='utf-8') as f:
        raw_data = json.load(f)
    
    # è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
    processed_data = []
    for item in raw_data:
        # ä»assistantçš„å›ç­”ä¸­æå–çœŸå®æ ‡æ³¨
        assistant_content = item["messages"][1]["content"]
        image_path = item["images"][0]
        
        # æå–answeræ ‡ç­¾å†…å®¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        extracted_answer = extract_answer_from_tags(assistant_content)
        
        # è§£æçœŸå®æ ‡æ³¨
        gt_bboxes = parse_bbox_from_text(assistant_content)
        gt_has_abnormality = len(gt_bboxes) > 0
        
        # åˆ›å»ºç»Ÿä¸€æ ¼å¼çš„æ•°æ®é¡¹
        data_item = {
            "image": image_path,
            "annotations": [{"bbox": bbox} for bbox in gt_bboxes],  # ç›´æ¥ä½¿ç”¨ç›¸å¯¹åæ ‡
            "gt_bboxes_relative": gt_bboxes,  # ä¿å­˜ç›¸å¯¹åæ ‡
            "has_abnormality": gt_has_abnormality,
            "raw_annotation": assistant_content,
            "extracted_answer": extracted_answer  # ä¿å­˜æå–çš„ç­”æ¡ˆ
        }
        processed_data.append(data_item)
    
    print(f"æ•°æ®åŠ è½½å®Œæˆ:")
    print(f"  æ€»æ ·æœ¬æ•°: {len(processed_data)}")
    print(f"  æœ‰ç—…å˜æ ·æœ¬: {sum(1 for item in processed_data if item['has_abnormality'])}")
    print(f"  æ— ç—…å˜æ ·æœ¬: {sum(1 for item in processed_data if not item['has_abnormality'])}")
    
    return processed_data

def evaluate_model_vllm(model_name: str, test_file: str, api_url: str = "http://127.0.0.1:8000/v1", 
                       output_file: str = None, max_samples: int = None,
                       iou_thresholds: List[float] = [0.3, 0.5, 0.7]):
    """
    ä½¿ç”¨VLLM APIè¯„ä¼°æ¨¡å‹æ€§èƒ½
    
    Args:
        model_name (str): æ¨¡å‹åç§°
        test_file (str): æµ‹è¯•æ–‡ä»¶è·¯å¾„
        api_url (str): VLLM APIæœåŠ¡åœ°å€
        output_file (str): è¾“å‡ºç»“æœæ–‡ä»¶è·¯å¾„
        max_samples (int): æœ€å¤§æµ‹è¯•æ ·æœ¬æ•°é‡
        iou_thresholds (List[float]): IoUé˜ˆå€¼åˆ—è¡¨
        
    Returns:
        tuple: (æœ€ç»ˆæŒ‡æ ‡, ç»“æœåˆ—è¡¨)
    """
    # åŠ è½½æµ‹è¯•æ•°æ®
    test_data = load_test_data_improved(test_file)
    
    if max_samples:
        test_data = test_data[:max_samples]
        print(f"é™åˆ¶æµ‹è¯•æ ·æœ¬æ•°é‡ä¸º: {max_samples}")
    
    print(f"æµ‹è¯•æ ·æœ¬æ€»æ•°: {len(test_data)}")
    
    # åˆå§‹åŒ–VLLMåˆ†ç±»å™¨
    classifier = VLLMGroundingClassifier(model_name, api_url=api_url)
    
    # å­˜å‚¨ç»“æœ
    results = []
    
    print("å¼€å§‹è¯„ä¼°...")
    for i, item in enumerate(tqdm(test_data, desc="è¯„ä¼°è¿›åº¦")):
        image_path = item['image']
        
        # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
        if not os.path.exists(image_path):
            print(f"å›¾ç‰‡ä¸å­˜åœ¨: {image_path}")
            continue
        
        # ç”Ÿæˆé¢„æµ‹
        prediction = classifier.detect(image_path)
        print("prediction:", prediction)
        
        # ä»é¢„æµ‹ç»“æœä¸­æå–answer
        extracted_prediction_answer = extract_answer_from_tags(prediction)
        
        result = {
            "image": item["image"],
            "ground_truth": item["annotations"],
            "gt_bboxes_relative": item["gt_bboxes_relative"],
            "gt_has_abnormality": item["has_abnormality"],
            "prediction": prediction,
            "raw_annotation": item.get("raw_annotation", ""),
            "extracted_answer": item.get("extracted_answer", ""),  # ä¿ç•™GTçš„extracted_answer
            "extracted_prediction_answer": extracted_prediction_answer  # æ–°å¢ï¼šä»é¢„æµ‹ä¸­æå–çš„answer
        }
        results.append(result)
        
        # æ‰“å°è¿›åº¦ä¿¡æ¯
        if (i + 1) % 10 == 0:
            print(f"å·²å¤„ç† {i + 1}/{len(test_data)} ä¸ªæ ·æœ¬")
    
    # è¯„ä¼°ç»“æœ
    final_metrics = evaluate_results_improved(results, iou_thresholds)
    
    # ä¿å­˜ç»“æœ
    if output_file:
        print(f"\nä¿å­˜ç»“æœåˆ°: {output_file}")
        output_data = {
            'model_info': {
                'model_name': model_name,
                'api_url': api_url,
                'total_samples': len(results)
            },
            'final_metrics': final_metrics,
            'detailed_results': results,
            'summary': {
                'total_samples': len(results),
                'model_name': model_name,
                'test_file': test_file
            }
        }
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(output_file), exist_ok=True)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
    
    return final_metrics, results

def evaluate_results_improved(results: List[Dict[str, Any]], 
                             iou_thresholds: List[float] = [0.3, 0.5, 0.7]) -> Dict[str, Any]:
    """
    æ”¹è¿›çš„è¯„ä¼°å‡½æ•°
    
    Args:
        results: ç»“æœåˆ—è¡¨
        iou_thresholds: IoUé˜ˆå€¼åˆ—è¡¨
        
    Returns:
        Dict[str, Any]: è¯„ä¼°æŒ‡æ ‡
    """
    # æŒ‰IoUé˜ˆå€¼ç»Ÿè®¡çš„æŒ‡æ ‡
    iou_metrics = {}
    for iou_th in iou_thresholds:
        iou_metrics[f"iou_{iou_th}"] = {
            "correct_samples": 0,
            "total_samples": 0,
            "true_negatives": 0,
            "false_positives": 0,
            "false_negatives": 0,
            "true_positives": 0,
            "low_iou_or_f1": 0
        }
    
    # ä¸“é—¨ç»Ÿè®¡"çœŸå®æœ‰æ¡†ä¸”é¢„æµ‹æœ‰æ¡†"æƒ…å†µçš„IoUå€¼
    both_has_bbox_ious = []
    
    # ç”¨äºå®æ—¶ç»Ÿè®¡mean_iouçš„å˜é‡
    all_ious = []
    samples_with_bbox = 0
    
    for i, result in enumerate(results):
        # è§£æé¢„æµ‹ç»“æœ
        pred_text = result["prediction"]
        pred_bboxes_relative, pred_has_abnormality = parse_prediction_text_improved(pred_text)
        
        # è·å–çœŸå®æ ‡æ³¨
        gt_bboxes_relative = result["gt_bboxes_relative"]
        gt_bboxes = [bbox for bbox in gt_bboxes_relative]  # ç›´æ¥ä½¿ç”¨ç›¸å¯¹åæ ‡
        gt_has_abnormality = result["gt_has_abnormality"]
        
        # ä¸“é—¨è®¡ç®—"çœŸå®æœ‰æ¡†ä¸”é¢„æµ‹æœ‰æ¡†"æƒ…å†µçš„IoU
        if gt_has_abnormality and pred_has_abnormality and len(gt_bboxes) > 0 and len(pred_bboxes_relative) > 0:
            sample_ious = []
            for pred_bbox in pred_bboxes_relative:
                for gt_bbox in gt_bboxes:
                    iou = calculate_iou(pred_bbox, gt_bbox)
                    sample_ious.append(iou)
                    both_has_bbox_ious.append(iou)
                    all_ious.append(iou)  # æ·»åŠ åˆ°å…¨å±€IoUåˆ—è¡¨
            
            # è®¡ç®—è¯¥æ ·æœ¬çš„æœ€å¤§IoU
            if sample_ious:
                max_sample_iou = max(sample_ious)
            else:
                max_sample_iou = 0.0
            
            samples_with_bbox += 1
        else:
            max_sample_iou = 0.0
        
        # å®æ—¶æ‰“å°mean_iouï¼ˆæ¯10ä¸ªæ ·æœ¬æ‰“å°ä¸€æ¬¡ï¼‰
        if (i + 1) % 10 == 0 and all_ious:
            current_mean_iou = np.mean(all_ious)
            print(f"ğŸ“Š å·²å¤„ç† {i + 1}/{len(results)} ä¸ªæ ·æœ¬ï¼Œå½“å‰mean_iou: {current_mean_iou:.4f} (åŸºäº {len(all_ious)} ä¸ªIoUå€¼)")
        
        # å¯¹æ¯ä¸ªIoUé˜ˆå€¼è¿›è¡Œè¯„ä¼°
        for iou_th in iou_thresholds:
            eval_result = evaluate_detection_improved(
                pred_bboxes_relative, gt_bboxes, pred_has_abnormality, gt_has_abnormality, iou_th
            )
            
            metrics_key = f"iou_{iou_th}"
            iou_metrics[metrics_key]["total_samples"] += 1
            
            if eval_result["correct"]:
                iou_metrics[metrics_key]["correct_samples"] += 1
            
            # ç»Ÿè®¡å„ç§æƒ…å†µ
            case = eval_result["case"]
            if case == "true_negative":
                iou_metrics[metrics_key]["true_negatives"] += 1
            elif case == "false_positive":
                iou_metrics[metrics_key]["false_positives"] += 1
            elif case == "false_negative":
                iou_metrics[metrics_key]["false_negatives"] += 1
            elif case == "true_positive":
                iou_metrics[metrics_key]["true_positives"] += 1
            elif case == "low_iou_or_f1":
                iou_metrics[metrics_key]["low_iou_or_f1"] += 1
    
    # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
    final_metrics = {
        "total_samples": len(results),
        "samples_with_bbox": samples_with_bbox,
        "mean_iou_all": np.mean(all_ious) if all_ious else 0.0,
        "mean_iou_both_has_bbox": np.mean(both_has_bbox_ious) if both_has_bbox_ious else 0.0,
        "iou_metrics": iou_metrics
    }
    
    # è®¡ç®—æ¯ä¸ªIoUé˜ˆå€¼çš„å‡†ç¡®ç‡
    for iou_th in iou_thresholds:
        metrics_key = f"iou_{iou_th}"
        total = iou_metrics[metrics_key]["total_samples"]
        correct = iou_metrics[metrics_key]["correct_samples"]
        accuracy = correct / total if total > 0 else 0.0
        iou_metrics[metrics_key]["accuracy"] = accuracy
    
    # æ‰“å°ç»“æœ
    print(f"\nğŸ¯ === æœ€ç»ˆè¯„ä¼°ç»“æœ ===")
    print(f"æ€»æ ·æœ¬æ•°é‡: {final_metrics['total_samples']}")
    print(f"æœ‰æ¡†æ ·æœ¬æ•°é‡: {final_metrics['samples_with_bbox']}")
    print(f"æ‰€æœ‰IoUçš„å¹³å‡å€¼: {final_metrics['mean_iou_all']:.4f}")
    print(f"åŒæ–¹éƒ½æœ‰æ¡†æ—¶çš„å¹³å‡IoU: {final_metrics['mean_iou_both_has_bbox']:.4f}")
    
    for iou_th in iou_thresholds:
        metrics_key = f"iou_{iou_th}"
        metrics = iou_metrics[metrics_key]
        print(f"\nIoUé˜ˆå€¼ {iou_th}:")
        print(f"  å‡†ç¡®ç‡: {metrics['accuracy']:.4f}")
        print(f"  æ­£ç¡®æ ·æœ¬: {metrics['correct_samples']}/{metrics['total_samples']}")
        print(f"  çœŸé˜´æ€§: {metrics['true_negatives']}")
        print(f"  å‡é˜³æ€§: {metrics['false_positives']}")
        print(f"  å‡é˜´æ€§: {metrics['false_negatives']}")
        print(f"  çœŸé˜³æ€§: {metrics['true_positives']}")
        print(f"  ä½IoU/F1: {metrics['low_iou_or_f1']}")
    
    return final_metrics

def main():
    """
    ä¸»å‡½æ•°
    """
    parser = argparse.ArgumentParser(description='ä½¿ç”¨VLLMè¯„ä¼°åŒ»ç–—æ ‡æ¡†æ¨¡å‹ - 32Bç‰ˆæœ¬')
    parser.add_argument('--model_name', type=str, 
                       default='/data0/zhuoxu/yihong/code/Qwen2.5-VL-32B-Instruct', 
                       help='VLLMéƒ¨ç½²çš„æ¨¡å‹åç§°')
    parser.add_argument('--test_file', type=str, 
                       default='/data0/zhuoxu/yihong/code/EasyR1-main/eval_data/test_grounding_balanced.json', 
                       help='æµ‹è¯•æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--api_url', type=str, 
                       default='http://127.0.0.1:8000/v1', 
                       help='VLLM APIæœåŠ¡åœ°å€')
    parser.add_argument('--output_file', type=str, 
                       default='/data0/zhuoxu/yihong/code/LLaMA-Factory-main/eval_result/Qwen2.5-VL-32B-VLLM-Grounding.json', 
                       help='è¾“å‡ºç»“æœæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--max_samples', type=int, help='æœ€å¤§æµ‹è¯•æ ·æœ¬æ•°é‡')
    
    args = parser.parse_args()
    
    # è¿è¡Œè¯„ä¼°
    metrics, results = evaluate_model_vllm(
        model_name=args.model_name,
        test_file=args.test_file,
        api_url=args.api_url,
        output_file=args.output_file,
        max_samples=args.max_samples
    )
    
    print(f"\nğŸ† è¯„ä¼°å®Œæˆï¼ä¸»è¦æŒ‡æ ‡:")
    print(f"å¹³å‡IoU: {metrics['mean_iou_all']:.4f}")
    print(f"IoU@0.5å‡†ç¡®ç‡: {metrics['iou_metrics']['iou_0.5']['accuracy']:.4f}")
    print(f"\nç»“æœå·²ä¿å­˜åˆ°: {args.output_file}")

if __name__ == "__main__":
    # é…ç½®å‚æ•°
    TEST_FILE = "/data0/zhuoxu/yihong/code/EasyR1-main/eval_data/test_grounding_balanced.json"
    MODEL_NAME = "/data0/zhuoxu/yihong/code/Qwen2.5-VL-32B-Instruct"  # æ ¹æ®å®é™…éƒ¨ç½²çš„æ¨¡å‹åç§°è°ƒæ•´
    API_URL = "http://127.0.0.1:8000/v1"  # VLLMæœåŠ¡åœ°å€
    OUTPUT_FILE = "/data0/zhuoxu/yihong/code/LLaMA-Factory-main/eval_result/Qwen2.5-VL-32B-VLLM-Grounding.json"
    
    # è¿è¡Œè¯„ä¼°
    main()