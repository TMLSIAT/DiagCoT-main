### 注意：合并LoRA适配器时请勿使用量化模型或quantization_bit参数

### 模型配置
model_name_or_path: Qwen2.5-VL-32B-Instruct
adapter_name_or_path: /data0/zhuoxu/yihong/code/DiagCoT-main/LLaMA-Factory-main/saves/tran_Qwen2.5_vl_32B_lora
template: qwen2_vl
trust_remote_code: true

### 导出配置
export_dir:  /data0/zhuoxu/yihong/code/DiagCoT-main/LLaMA-Factory-main/saves/tran_Qwen2.5_vl_32B_lora/mergerd_model
export_size: 5
export_device: cpu
export_legacy_format: false 